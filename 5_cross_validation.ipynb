{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clase 10: Validación cruzada.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNm-dDcDWYET"
      },
      "source": [
        "# Más sobre evaluación de modelos y selección de features (segunda parte)\n",
        "\n",
        "En este segundo notebook vamos a ver otra forma distinta (y más usada) de estimar la performance de modelos en vez del *train-test split*.\n",
        "\n",
        "Seguimos trabajando con los datos de INTA, así que repetimos el proceso para cargarlos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTujCTikWGp6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d48b95f1-3b8c-462c-d295-e62a520c6445"
      },
      "source": [
        "# Como siempre, tratamos de traer todos los paquetes al ppio\n",
        "from google.colab import drive # Para montar nuestro drive en la consola\n",
        "import matplotlib.pylab as plt # Para gráficos\n",
        "import numpy as np # Para manejo de arrays, operaciones matemáticas, etc.\n",
        "from sklearn.linear_model import LogisticRegression # El método de regresión logística que vamos a usar\n",
        "import pandas as pd # Para manejo de base de datos\n",
        "\n",
        "# Traemos los datos\n",
        "drive.mount('/content/drive') # Montamos nuestra unidad de Google Drive\n",
        "\n",
        "filename = '/content/drive/My Drive/LaboDatos2021/datosDiariosSanFernandoINTA.xls'\n",
        "\n",
        "d = pd.read_excel(filename) # Levantamos los datos, en este caso, con el método pd.read_excel"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff6MSZfVW9Lz"
      },
      "source": [
        "Luego, filtramos el dataframe descartando columnas con datos faltantes, seleccionamos un subconjunto de columnas, y las renombramos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTay790UXBEJ"
      },
      "source": [
        "d_filtrado = d[['Temperatura_Abrigo_150cm_Maxima',\n",
        "                'Temperatura_Abrigo_150cm_Minima',\n",
        "                'Precipitacion_Pluviometrica',\n",
        "                'Velocidad_Viento_Maxima',\n",
        "                'Rocio_Medio',\n",
        "                'Humedad_Media', 'Tesion_Vapor_Media']].dropna().copy() # Nos quedamos con ciertos campos del data set, para facilitar el trabajo. Y para limitarlo.\n",
        "                                                  # Notar que primero aplicamos el método .dropna() para eliminar filas que tengan alguna columna con NaN \n",
        "                                                  # Ademas, el metodo copy() nos asegura que estemos creando un nuevo dataframe \n",
        "d_filtrado.rename({'Temperatura_Abrigo_150cm_Maxima' : 'temperaturaMaxima',\n",
        "                   'Temperatura_Abrigo_150cm_Minima' : 'temperaturaMinima',\n",
        "                   'Precipitacion_Pluviometrica' : 'precipitacion',\n",
        "                   'Humedad_Media' : 'humedad',\n",
        "                   'Rocio_Medio' : 'rocio',\n",
        "                   'Velocidad_Viento_Maxima' : 'viento', 'Tesion_Vapor_Media': 'vapor'},\n",
        "                  axis = 1,\n",
        "                  inplace = True) # Esto toma como input un diccionario en el cual las llaves son los nombres actuales de columnas, y los valores los nombres nuevos (a los que queremos renombrar)\n",
        "                                  # axis = 1 es porque queremos renombrar columnas, y inplace=True es porque queremos \"pisar\" el dataframe al renombrarlo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gnj818t9XC37"
      },
      "source": [
        "Finalmente, construimos una variable con las etiquetas de los días lluviosos.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVZQD9ZdXFjl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8f042bc-bcb4-48ee-e9f8-9ac19021b0d1"
      },
      "source": [
        "d_filtrado['llueveNollueve'] = 0 # empezamos con una columna llena de 0. \n",
        "indice =  d_filtrado['precipitacion'] > 0  # esto me da los valores del indice para los cuales hay precipitacion mayor a 0\n",
        "d_filtrado.loc[indice, 'llueveNollueve'] = 1 # entonces para esos valores del indice pongo 1, porque en el dia correspondiente, llovio\n",
        "\n",
        "d_filtrado['llueveNollueve'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    717\n",
              "1    337\n",
              "Name: llueveNollueve, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcrlZhAcXV39"
      },
      "source": [
        "# Validación cruzada estratificada\n",
        "\n",
        "Empecemos con un modelo que incorpora features elevadas al cuadrado, cubo., etc. para darle más flexibilidad al modelo. \n",
        "\n",
        "Calculemos el AUC y ploteemos la curva ROC para los datos de entrenamiento y de evaluación siguiendo un train-test split con 70-30.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhq6bzhiXjDy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "outputId": "d806b174-21dc-4ed4-fe29-b1aee44222cb"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Definamos la matriz X\n",
        "campos = ['temperaturaMinima', 'temperaturaMaxima', 'humedad', 'rocio', 'vapor'] # Lista que contiene las features de interés.\n",
        "X = d_filtrado[campos].values # En este caso no hace falta reshapear, porque ya tiene la forma que queremos\n",
        "y = d_filtrado['llueveNollueve'] # Nuestra etiqueta sigue siende la misma de antes\n",
        "\n",
        "X_temp = X\n",
        "for i in np.arange(2,6):\n",
        "    X_temp = np.concatenate((X_temp,X**i), axis=1)\n",
        "X_1 = X_temp\n",
        " \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_1, y, test_size=0.3) # armo el split\n",
        "\n",
        "scaler = MinMaxScaler() # escaleo por separado ambos sets\n",
        "scaler.fit(X_train) \n",
        "X_train = scaler.transform(X_train)\n",
        "\n",
        "scaler = MinMaxScaler() # escaleo por separado ambos sets\n",
        "scaler.fit(X_test) \n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "regLog_1 = LogisticRegression(penalty = 'none', max_iter=10000) # Inicializamos nuevamente el modelo. max_iter es la cantidad de iteraciones maximas del algoritmo de optimizacion de parametros antes de detenerse.\n",
        "regLog_1.fit(X_train, y_train) # Ajustamos el modelo con los datos de entrenamiento\n",
        "\n",
        "probas_train = regLog_1.predict_proba(X_train)  # probabilidades con datos de entrenamiento\n",
        "probas_test = regLog_1.predict_proba(X_test)  # probabilidades con datos de evaluación\n",
        "\n",
        "fpr_train, tpr_train, thresholds_train = roc_curve(y_train, probas_train[:,1]) # para plotear curva ROC con datos de entrenamiento\n",
        "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, probas_test[:,1]) # para plotear curva ROC con datos de evaluacion\n",
        "\n",
        "auc_train = roc_auc_score(y_train, probas_train[:,1]) #  AUC con datos de entrenamiento\n",
        "auc_test = roc_auc_score(y_test, probas_test[:,1]) #  AUC con datos de evaluación\n",
        "\n",
        "# para plotear ROC (codigo de un notebook anterior)\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (10,7))\n",
        "ax.set_title('Verdaderos positivos vs. falsos positivos')\n",
        "ax.plot(fpr_train,tpr_train, label = \"Entrenamiento\") # graficamos la curva ROC para el set de entrenamiento\n",
        "ax.plot(fpr_test,tpr_test, label = \"Evaluacion\") # graficamos la curva ROC para el set de evaluacion\n",
        "\n",
        "ax.set_xlabel('Tasa de falsos positivos') # Etiqueta del eje x\n",
        "ax.set_ylabel('Tasa de verdaderos positivos') # Etiqueta del eje y\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "print('AUC entrenamiento: {}'.format(round(auc_train,4)))  \n",
        "print('AUC evaluacion: {}'.format(round(auc_test,4)))  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC entrenamiento: 0.7698\n",
            "AUC evaluacion: 0.6974\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJ79OqTfaUxz"
      },
      "source": [
        "Podemos darle Play varias veces al bloque de código anterior. Vamos a ver que hay una variabilidad natural en las curvas, aunque en general el AUC de evaluacion será menor que el de entrenamiento, debido al overfitting.\n",
        "\n",
        "**Un problema del train-test split es que depende mucho de qué casos fueron a parar a cada uno de los conjuntos.**\n",
        "\n",
        "Si tuvimos \"suerte\" entonces los casos del conjunto de entrenamiento serán muy informativos y el clasificador tendrá buena performance. Pero sino, no. Entonces esto fluctúa dependiendo del azar.\n",
        "\n",
        "Otro problema es que el train-test split produce predicciones no sesgadas por overfitting **únicamente para los casos que fueron al test set.** Si quisieramos una predicción del modelo para todos los casos, entonces para aquellos en el train set obtendríamos una predicción más certera de lo esperable realmente.\n",
        "\n",
        "Una forma de atenuar estos problemas es usar **validación cruzada estratificada con K folds**, la cual funciona de la siguiente manera:\n",
        "\n",
        "1.   Se dividen los datos en K subconjuntos de forma tal que la prevalencia de ambas clases esté balanceada en cada subconjunto.\n",
        "2.   Se elige uno de esos subconjuntos y se lo designa set de evaluación. Todos los demás son sets de entrenamiento. Se entrena entonces al modelo usando estos datos para evaluación y entrenamiento, y se genera una predicción para cada uno de los datos en el conjunto que fue elegido como evaluación.\n",
        "3.   Se repite el proceso usando cada uno de los K subconjuntos para evaluación exactamente una vez.\n",
        "\n",
        "De esta forma, tenemos que todos los datos fueron usados una vez para evaluación y al menos una vez para entrenamiento. Además, tenemos una predicción para cada uno de los casos, y esta predicción no está afectada por overfitting (porque ese caso no fue usado en entrenamiento).\n",
        "\n",
        "Veamos como funciona implementarlo en scikit-learn.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iAhkd-qcH3n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4bd2c3d-e118-4830-f918-77e51a221317"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Definamos la matriz X\n",
        "campos = ['temperaturaMinima', 'temperaturaMaxima', 'humedad', 'rocio', 'vapor'] # Lista que contiene las features de interés.\n",
        "X = d_filtrado[campos].values # En este caso no hace falta reshapear, porque ya tiene la forma que queremos\n",
        "y = np.array(d_filtrado['llueveNollueve']) # Nuestra etiqueta sigue siende la misma de antes\n",
        "\n",
        "X_temp = X\n",
        "for i in np.arange(2,6):\n",
        "    X_temp = np.concatenate((X_temp,X**i), axis=1)\n",
        "X_1 = X_temp\n",
        " \n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True) # 5 folds es un número típico si tenemos suficientes datos. Pedimos shuffle=True para que sea al azar la separación en subgrupos\n",
        "skf.get_n_splits(X_1, y) # arma los folds a partir de los datos\n",
        "\n",
        "auc_values = [] # aca es donde van a ir a parar los AUCs de cada fold\n",
        "scores = np.array([])     # aca es donde van a ir a parar los scores computados para todos los casos\n",
        "indices = np.array([])    # aca es donde van a ir a parar los indices correspondientes a las entradas de scores\n",
        "\n",
        "for train_index, test_index in skf.split(X_1, y): # va generando los indices que corresponden a train y test en cada fold\n",
        "    X_train, X_test = X_1[train_index], X_1[test_index] # arma que es dato de entrenamiento y qué es dato de evaluación\n",
        "    y_train, y_test = y[train_index], y[test_index]     # idem con los targets\n",
        "\n",
        "    regLog_1 = LogisticRegression(penalty = 'none', max_iter=10000) # Inicializamos nuevamente el modelo. max_iter es la cantidad de iteraciones maximas del algoritmo de optimizacion de parametros antes de detenerse.\n",
        "    regLog_1.fit(X_train, y_train) # Ajustamos el modelo con los datos de entrenamiento\n",
        "\n",
        "    probas_test = regLog_1.predict_proba(X_test)  # probabilidades con datos de evaluación\n",
        "    fpr_test, tpr_test, thresholds_test = roc_curve(y_test, probas_test[:,1]) # para plotear curva ROC con datos de entrenamiento\n",
        "    auc_test = roc_auc_score(y_test, probas_test[:,1]) #  AUC con datos de evaluación\n",
        "\n",
        "    auc_values.append(auc_test)\n",
        "    scores = np.concatenate((scores,probas_test[:,1]),axis=0)\n",
        "    indices = np.concatenate((indices,test_index),axis=0)\n",
        "\n",
        "print(\"Estos son los valores AUC para cada fold:\")\n",
        "print(auc_values)\n",
        "print(\"Estos es el promedio de todos los AUC:\")\n",
        "print(np.mean(auc_values))\n",
        "print(\"Estos son las probabilidades para cada sample:\")\n",
        "print(scores)\n",
        "print(\"Esta es la forma en que quedaron ordenados las entradas del vector anterior (indices):\")\n",
        "print(indices)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estos son los valores AUC para cada fold:\n",
            "[0.7159605100781572, 0.809543397778692, 0.6983830845771144, 0.748134328358209, 0.7340569877883311]\n",
            "Estos es el promedio de todos los AUC:\n",
            "0.7412156617161008\n",
            "Estos son las probabilidades para cada sample:\n",
            "[0.17695431 0.19192147 0.22520072 ... 0.26286311 0.19942934 0.48323599]\n",
            "Esta es la forma en que quedaron ordenados las entradas del vector anterior (indices):\n",
            "[   4.    6.    8. ... 1039. 1041. 1052.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhtCGgHtgnv2"
      },
      "source": [
        "Por último, también se puede seguir un esquema de validación tipo \"leave one out\" (dejar uno afuera). Esta estrategia da un mejor estimativo de la performance del clasificador sobre los datos, pero es más costoso computacionalmente. Supongamos que tenemos $N$ samples, entonces los dividimos en $N$ grupos de entrenamiento y validación, donde los conjuntos de validación tienen un solo elemento, que va siendo cada uno de los samples en mi dataset, y los conjuntos de entrenamiento tienen todos los samples menos el que quedó en el conjunto de evaluación. **Así, todos los datos posibles se usan para estimar la clase de cada sample en el dataset.**\n",
        "\n",
        "```\n",
        "# sklearn.model_selection.LeaveOneOut[source]¶\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCvvUBnbhkLc"
      },
      "source": [
        "# Para llevarse de este notebook\n",
        "\n",
        "*   El train-test split tiene la desventaja de que dependiendo del azar, algunos datos se usan para entrenar y otros para evaluar, y que no obtenemos una estimación no sesgada de todos los samples en el dataset, únicamente de ellos que fueron a parar al test set.\n",
        "*   Esto se puede resolver usando la validación cruzada estratificada con K-folds:\n",
        "\n",
        "\n",
        "```\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "skf.get_n_splits(X_1, y) \n",
        "for train_index, test_index in skf.split(X_1, y):\n",
        "\n",
        "```\n",
        "\n",
        "Dentro del for loop (que se ejecuta tantas veces como folds fueron elegidos), las variables train_index y test_index van tomando los valores que corresponden a cada fold en el cual se intenta balancear las cantidad de ejemplos de cada clase.\n",
        "\n",
        "*   Otra forma de hacer esto es con \"leave one out\", que es más costoso computacionalmente:\n",
        "\n",
        "```\n",
        "# sklearn.model_selection.LeaveOneOut[source]¶\n",
        "```\n",
        "\n",
        "pero que usa todos los datos posibles para estimar la etiqueta de cada sample.\n",
        "\n"
      ]
    }
  ]
}